select(ds, yhat, yhat_lower, yhat_upper, trend_lower, trend_upper) %>%
rename(Prophet_lower_80      = yhat_lower,
Prophet_lower_95      = trend_lower,
Prophet_upper_80      = yhat_upper,
Prophet_upper_95      = trend_upper,
Prophet_mean          = yhat)
fcast_Prohet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2)
View(fcast_Prohet_data)
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2)
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2, by = "ds")
View(fcast_Prophet)
View(fcast_Prohet_data)
View(fcast_Prophet_data)
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2)
View(fcast_Prophet_data)
View(fcast_Prophet)
# Testing data visualization
ggplot(fcast_Prophet_data, aes(x = date, y = actual)) +
# Observed values from 2020 to 2025
geom_line(color = "black", size = 1) +
# ARIMA projections
geom_line(aes(y = Prophet_mean), color = "brown4", size = 0.8, linetype = "dashed") +
geom_ribbon(data = subset(fcast_Prophet_data, is.na(actual)),
aes(ymin = Prophet_lower_95, ymax = Prophet_upper_95), fill = "brown4", alpha = 0.2) +
geom_ribbon(data = subset(fcast_Prophet_data, is.na(actual)),
aes(ymin = Prophet_lower_80, ymax = Prophet_upper_80), fill = "brown4", alpha = 0.3) +
# Plot labels and theme
labs(title = "Projected Values: Prophet Model",
x = "Date",
y = "Value") +
theme_bw() +
scale_x_date(date_breaks = "12 month", date_labels = "%Y") +
scale_y_continuous(labels = comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Testing data visualization
ggplot(fcast_Prophet_data, aes(x = ds, y = actual)) +
# Observed values from 2020 to 2025
geom_line(color = "black", size = 1) +
# ARIMA projections
geom_line(aes(y = Prophet_mean), color = "brown4", size = 0.8, linetype = "dashed") +
geom_ribbon(data = subset(fcast_Prophet_data, is.na(actual)),
aes(ymin = Prophet_lower_95, ymax = Prophet_upper_95), fill = "brown4", alpha = 0.2) +
geom_ribbon(data = subset(fcast_Prophet_data, is.na(actual)),
aes(ymin = Prophet_lower_80, ymax = Prophet_upper_80), fill = "brown4", alpha = 0.3) +
# Plot labels and theme
labs(title = "Projected Values: Prophet Model",
x = "Date",
y = "Value") +
theme_bw() +
scale_x_date(date_breaks = "12 month", date_labels = "%Y") +
scale_y_continuous(labels = comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2) %>%
data.frame()
# Testing data visualization
ggplot(fcast_Prophet_data, aes(x = ds, y = actual)) +
# Observed values from 2020 to 2025
geom_line(color = "black", size = 1) +
# ARIMA projections
geom_line(aes(y = Prophet_mean), color = "brown4", size = 0.8, linetype = "dashed") +
geom_ribbon(data = subset(fcast_Prophet_data, is.na(actual)),
aes(ymin = Prophet_lower_95, ymax = Prophet_upper_95), fill = "brown4", alpha = 0.2) +
geom_ribbon(data = subset(fcast_Prophet_data, is.na(actual)),
aes(ymin = Prophet_lower_80, ymax = Prophet_upper_80), fill = "brown4", alpha = 0.3) +
# Plot labels and theme
labs(title = "Projected Values: Prophet Model",
x = "Date",
y = "Value") +
theme_bw() +
scale_x_date(date_breaks = "12 month", date_labels = "%Y") +
scale_y_continuous(labels = comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
View(fcast_TS_data)
View(fcast_Prophet_data)
head(forecast_Prophet_data,10)
head(fcast_Prophet_data,10)
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2) %>%
# Organizing data frame
fcast_Prophet_df <- data.frame(
date = as.Date(fcast_Prophet_data$ds),
actual = as.numeric(fcast_ARIMA_data[,1]),
Prophet_lower_80 = as.numeric(fcast_Prophet_data$Prophet_lower_80),
Prophet_lower_95 = as.numeric(fcast_Prophet_data$Prophet_lower_95),
Prophet_upper_80 = as.numeric(fcast_Prophet_data$Prophet_upper_80),
Prophet_upper_95 = as.numeric(fcast_Prophet_data$Prophet_upper_95),
Prophet_mean     = as.numeric(fcast_Prophet_data$Prophet_mean)
)
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2) %>%
# Organizing data frame
fcast_Prophet_df <- data.frame(
date = as.Date(fcast_Prophet_data$ds),
actual = as.numeric(fcast_ARIMA_data[,1]),
Prophet_lower_80 = as.numeric(fcast_Prophet_data$Prophet_lower_80),
Prophet_lower_95 = as.numeric(fcast_Prophet_data$Prophet_lower_95),
Prophet_upper_80 = as.numeric(fcast_Prophet_data$Prophet_upper_80),
Prophet_upper_95 = as.numeric(fcast_Prophet_data$Prophet_upper_95),
Prophet_mean     = as.numeric(fcast_Prophet_data$Prophet_mean))
fcast_Prophet_data <- full_join(fcast_Prophet_1,fcast_Prophet_2)
# Organizing data frame
fcast_Prophet_df <- data.frame(
date = as.Date(fcast_Prophet_data$ds),
actual = as.numeric(fcast_ARIMA_data[,1]),
Prophet_lower_80 = as.numeric(fcast_Prophet_data$Prophet_lower_80),
Prophet_lower_95 = as.numeric(fcast_Prophet_data$Prophet_lower_95),
Prophet_upper_80 = as.numeric(fcast_Prophet_data$Prophet_upper_80),
Prophet_upper_95 = as.numeric(fcast_Prophet_data$Prophet_upper_95),
Prophet_mean     = as.numeric(fcast_Prophet_data$Prophet_mean))
# Testing data visualization
ggplot(fcast_Prophet_df, aes(x = date, y = actual)) +
# Observed values from 2020 to 2025
geom_line(color = "black", size = 1) +
# ARIMA projections
geom_line(aes(y = Prophet_mean), color = "brown4", size = 0.8, linetype = "dashed") +
geom_ribbon(data = subset(fcast_Prophet_df, is.na(actual)),
aes(ymin = Prophet_lower_95, ymax = Prophet_upper_95), fill = "brown4", alpha = 0.2) +
geom_ribbon(data = subset(fcast_Prophet_df, is.na(actual)),
aes(ymin = Prophet_lower_80, ymax = Prophet_upper_80), fill = "brown4", alpha = 0.3) +
# Plot labels and theme
labs(title = "Projected Values: Prophet Model",
x = "Date",
y = "Value") +
theme_bw() +
scale_x_date(date_breaks = "12 month", date_labels = "%Y") +
scale_y_continuous(labels = comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("./2_code/Pipeline/07_combined_data.R")
View(multivariate_ts)
fit_VA <- VAR(data = multivariate_ts, p=1 )
View(fit_VA)
h <- 60
fcast_TS <- forecast(fit_VA, h=h)
fcast_TS <- forecast(fit_VA)
fit_VA <- VAR(data = multivariate_ts, p=1 )
forecast(fit_VA)
?VAR()
pacman::p_load(
# Core Data Manipulation and Tidying
dplyr,        # Data manipulation: filter, summarize, mutate, and more
tidyr,        # Data tidying: pivot, handle missing values, reshape
janitor,      # Clean messy data and create summary tables
forcats,      # Handle categorical variables (factors)
# Data Import and Export
readr,        # Read flat files (CSV, TSV) into tibbles
readxl,       # Read Excel files (.xls, .xlsx) into data frames
basedosdados, # Access Brazilian public data via BigQuery
httr,         # Perform HTTP requests for web API interactions
archive,      # Extract files from compressed archives (.zip, .tar.gz)
# Data Visualization
ggplot2,      # Create customizable visualizations with grammar of graphics
scales,       # Format axes and legends (percentages, currencies)
viridis,      # Colorblind-friendly color palettes
RColorBrewer, # Additional color palettes for plots
gridExtra,    # Arrange multiple grid-based plots on a page
ggfortify,    # Unified plotting interface for stats objects
grid,         # Low-level graphics system
# String Manipulation
stringr,      # Simple and consistent string manipulation functions
stringi,      # Advanced string manipulation with Unicode support
# Date-Time Handling
lubridate,    # Simplify date and time parsing and manipulation
# Geographic and Spatial Data
geobr,        # Access Brazilian geographic data (e.g., shapefiles)
deflateBR,    # Deflate nominal Brazilian Reais using price indexes
sf,           # Handle spatial/geographic data in R
# Reporting and Tables
gt,           # Create publication-quality tables
stargazer,    # Generate regression tables in LaTeX/HTML/text formats
# Machine Learning and Statistics
caret,        # Comprehensive machine learning framework
Metrics,      # Evaluate model performance (RMSE, MAE, etc.)
glmnet,       # Regularized generalized linear models (Lasso, Ridge)
earth,        # Multivariate Adaptive Regression Splines
vip,          # Variable Importance Plots
pdp,          # Partial Dependence Plots
car,          # Companion to Applied Regression (diagnostic functions)
DescTools,    # Tools for descriptive statistics
rsample,      # Functions for resampling data
# Time Series Analysis
plm,          # Panel data analysis (fixed/random effects models)
forecast,     # Time series forecasting functions and models
astsa,        # Applied statistical time series analysis
xts,          # Extensible time series class and methods
seasonal,     # Seasonal adjustment of time series
urca,         # Unit root and cointegration tests
fable,        # Modern time series modeling framework
tsibble,      # Tidy temporal data structures
prophet,      # Forecasting procedure for time series
vars
)
VARselect(multivariate_ts)
View(multivariate_ts)
source("./2_code/00_packages.R")
# 2. Loading data sets ---------------------------------------------------------
# Fleet stock per vehicle type and population
df_fleet_city         <- read_csv("./3_processed_data/df_fleet_city.csv")
df_fleet_state        <- read_csv("./3_processed_data/df_fleet_state.csv")
df_fleet_brazil       <- read_csv("./3_processed_data/df_fleet_brazil.csv")
# Vehicle price data
price_df              <- read_csv("./3_processed_data/fipe_price_monthly_trends_deflated.csv")
# Income distribution per state
income_data_wide_uf   <- read_csv("./3_processed_data/income_data_wide_uf.csv")
# 3. Data transformation for the models ----------------------------------------
## Data for the linear regressions ---------------------------------------------
## Adding price information and grouping by state
df_combined_state <- df_fleet_state %>%
left_join(price_df, by = "date") %>%
group_by(sigla_uf, date, year, month) %>%
summarize(diesel     = sum(Diesel),
ethanol    = sum(Ethanol),
gasoline   = sum(Gasoline),
other      = sum(Other),
electric   = sum(BEV),
PHEV       = sum(PHEV),
gas        = sum(gas),
population = sum(population),
mean_gas   = mean(mean_price_gasoline),
mean_hyb   = mean(mean_price_hybrid),
mean_ev    = mean(mean_price_electric),
median_gas = mean(median_price_gasoline),
median_hyb = mean(median_price_hybrid),
median_ev  = mean(median_price_electric),
min_gas    = mean(min_price_gasoline),
min_hyb    = mean(min_price_hybrid),
min_ev     = mean(min_price_electric)) %>%
mutate(ff_pc        = (gasoline+diesel)/population,
log_ff       = log(gasoline+diesel),
log_pop      = log(population))
## Adding income distribution data
df_combined_state <- df_combined_state %>%
left_join(income_data_wide_uf, by = c("year", "sigla_uf")) %>%
drop_na()
if (!file.exists(  "./3_processed_data/df_combined_state.csv")) {
write_csv(df_combined_state,
file = "./3_processed_data/df_combined_state.csv")
} else {
print("File already exists in the repository")
}
## Data for the univariate time series -----------------------------------------
start_year  <- 2020
start_month <- 01
df <-  df_fleet_state%>%
group_by(date) %>%
summarize(BEV=sum(BEV))
df_combined_state %>%
group_by(date) %>%
summarize(BEV=sum(electric))
fleet_df_ts <- df_combined_state %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100) %>%
group_by(date) %>%
summarize(
electric                   = sum(electric),
PHEV                       = sum(PHEV),
population                 = sum(population),
min_ev                     = mean(min_ev),
mean_gas                   = mean(mean_gas),
mean_hyb                   = mean(mean_hyb),
avg_taxable_income_50      = mean(avg_taxable_income_50),
avg_taxable_income_100     = mean(avg_taxable_income_100),
log_electric               = log(electric),
log_population             = log(population),
log_min_ev                 = log(min_ev),
log_mean_gas               = log(mean_gas),
log_mean_hyb               = log(mean_hyb),
log_avg_taxable_income_50  = log(avg_taxable_income_50),
log_avg_taxable_income_100 = log(avg_taxable_income_100)
) %>%
mutate(
electric   = if_else(date == as.Date("2018-06-01"), electric   / 2, electric),
population = if_else(date == as.Date("2018-06-01"), population / 2, population)
)
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_electric:log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
source("./2_code/00_packages.R")
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_electric:log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
start_year  <- 2020
start_month <- 01
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_electric:log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
fleet_df_ts
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_population:log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_population:log_avg_taxable_income_100)
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_population, log_mmin_ev, log_mean_gas, log_mean_hyb,
Ã¶pg_avg_taxable_income_50, log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_population, log_mmin_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
log_multivariate_ts <- fleet_df_ts %>%
select(date, year, month, log_population, log_min_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100) %>%
filter(year > 2019) %>%
arrange(date) %>%
ts(start = c(start_year, start_month), frequency = 12)
log_multivariate_ts <- fleet_df_ts %>%
filter(year > 2019) %>%
arrange(date) %>%
# Then select only numeric columns for the time series object
select(log_population, log_min_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100) %>%
# Create time series object without including date columns
ts(start = c(start_year, start_month), frequency = 12)
log_multivariate_ts <- fleet_df_ts %>%
filter(year > 2019) %>%
arrange(date) %>%
# Use dplyr::select explicitly to avoid namespace conflicts
dplyr::select(log_population, log_min_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100) %>%
as.matrix() %>%  # Convert to matrix first
ts(start = c(start_year, start_month), frequency = 12)
fleet_df_ts
multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100) %>%
group_by(date) %>%
summarize(
electric                   = sum(electric),
PHEV                       = sum(PHEV),
population                 = sum(population),
min_ev                     = mean(min_ev),
mean_gas                   = mean(mean_gas),
mean_hyb                   = mean(mean_hyb),
avg_taxable_income_50      = mean(avg_taxable_income_50),
avg_taxable_income_100     = mean(avg_taxable_income_100),
log_electric               = log(electric),
log_population             = log(population),
log_min_ev                 = log(min_ev),
log_mean_gas               = log(mean_gas),
log_mean_hyb               = log(mean_hyb),
log_avg_taxable_income_50  = log(avg_taxable_income_50),
log_avg_taxable_income_100 = log(avg_taxable_income_100)
) %>%
mutate(
electric   = if_else(date == as.Date("2018-06-01"), electric   / 2, electric),
population = if_else(date == as.Date("2018-06-01"), population / 2, population)
) %>%
select(date, log_electric:log_avg_taxable_income_100)
multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100) %>%
group_by(date) %>%
summarize(
electric                   = sum(electric),
PHEV                       = sum(PHEV),
population                 = sum(population),
min_ev                     = mean(min_ev),
mean_gas                   = mean(mean_gas),
mean_hyb                   = mean(mean_hyb),
avg_taxable_income_50      = mean(avg_taxable_income_50),
avg_taxable_income_100     = mean(avg_taxable_income_100),
log_electric               = log(electric),
log_population             = log(population),
log_min_ev                 = log(min_ev),
log_mean_gas               = log(mean_gas),
log_mean_hyb               = log(mean_hyb),
log_avg_taxable_income_50  = log(avg_taxable_income_50),
log_avg_taxable_income_100 = log(avg_taxable_income_100)
) %>%
mutate(
electric   = if_else(date == as.Date("2018-06-01"), electric   / 2, electric),
population = if_else(date == as.Date("2018-06-01"), population / 2, population)
)  %>%
ts(start = c(start_year, start_month), frequency = 12)
multivariate_ts <- df_combined_state %>%
filter(year > 2019)
multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100)
pacman::p_load(
# Core Data Manipulation and Tidying
dplyr,        # Data manipulation: filter, summarize, mutate, and more
tidyr,        # Data tidying: pivot, handle missing values, reshape
janitor,      # Clean messy data and create summary tables
forcats,      # Handle categorical variables (factors)
# Data Import and Export
readr,        # Read flat files (CSV, TSV) into tibbles
readxl,       # Read Excel files (.xls, .xlsx) into data frames
basedosdados, # Access Brazilian public data via BigQuery
httr,         # Perform HTTP requests for web API interactions
archive,      # Extract files from compressed archives (.zip, .tar.gz)
# Data Visualization
ggplot2,      # Create customizable visualizations with grammar of graphics
scales,       # Format axes and legends (percentages, currencies)
viridis,      # Colorblind-friendly color palettes
RColorBrewer, # Additional color palettes for plots
gridExtra,    # Arrange multiple grid-based plots on a page
ggfortify,    # Unified plotting interface for stats objects
grid,         # Low-level graphics system
# String Manipulation
stringr,      # Simple and consistent string manipulation functions
stringi,      # Advanced string manipulation with Unicode support
# Date-Time Handling
lubridate,    # Simplify date and time parsing and manipulation
# Geographic and Spatial Data
geobr,        # Access Brazilian geographic data (e.g., shapefiles)
deflateBR,    # Deflate nominal Brazilian Reais using price indexes
sf,           # Handle spatial/geographic data in R
# Reporting and Tables
gt,           # Create publication-quality tables
stargazer,    # Generate regression tables in LaTeX/HTML/text formats
# Machine Learning and Statistics
caret,        # Comprehensive machine learning framework
Metrics,      # Evaluate model performance (RMSE, MAE, etc.)
glmnet,       # Regularized generalized linear models (Lasso, Ridge)
earth,        # Multivariate Adaptive Regression Splines
vip,          # Variable Importance Plots
pdp,          # Partial Dependence Plots
car,          # Companion to Applied Regression (diagnostic functions)
DescTools,    # Tools for descriptive statistics
rsample,      # Functions for resampling data
# Time Series Analysis
plm,          # Panel data analysis (fixed/random effects models)
forecast,     # Time series forecasting functions and models
astsa,        # Applied statistical time series analysis
xts,          # Extensible time series class and methods
seasonal,     # Seasonal adjustment of time series
urca,         # Unit root and cointegration tests
fable,        # Modern time series modeling framework
tsibble,      # Tidy temporal data structures
prophet,      # Forecasting procedure for time series
vars
)
multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100)
multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100)
multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
select(sigla_uf, date, year, month,
diesel, ethanol, gasoline, other, electric, PHEV,
population,
mean_gas, mean_hyb, min_ev,
avg_taxable_income_50, avg_taxable_income_100)
log_multivariate_ts <- fleet_df_ts %>%
filter(year > 2019) %>%
arrange(date) %>%
dplyr::select(log_population, log_min_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100) %>%
ts(start = c(start_year, start_month), frequency = 12)
log_multivariate_ts <- fleet_df_ts %>%
filter(year > 2019)
fleet_df_ts
log_multivariate_ts <- df_fleet_brazil %>%
filter(year > 2019)
log_multivariate_ts <- df_fleet_brazil %>%
filter(year > 2019) %>%
arrange(date)
log_multivariate_ts <- df_fleet_brazil %>%
filter(year > 2019) %>%
arrange(date) %>%
dplyr::select(log_population, log_min_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100)
df_combined_state
df_fleet_state
log_multivariate_ts <- df_combined_state %>%
filter(year > 2019)
log_multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
arrange(date)
log_multivariate_ts <- df_combined_state %>%
filter(year > 2019) %>%
arrange(date) %>%
dplyr::select(log_population, log_min_ev, log_mean_gas, log_mean_hyb,
log_avg_taxable_income_50, log_avg_taxable_income_100)
source("C:/Users/joaov/Dropbox/R Assignments/master-thesis/2_code/Pipeline/07_combined_data.R", echo=TRUE)
source("C:/Users/joaov/Dropbox/R Assignments/master-thesis/2_code/Pipeline/07_combined_data.R", echo=TRUE)
