year <- as.numeric(substr(basename(file_path), 1, 4))
fleet_df <- read_excel(file_path)
# Aggregate municipal data at state level
fleet_state <- fleet_df %>%
group_by(UF, `Combustível Veículo`) %>%
summarize(Total = sum(`Qtd. Veículos`), .groups = 'drop')
# Data frame of total vehicles per state
vehicles_per_state <- fleet_state %>%
group_by(UF) %>%
summarise(total_vehicles = sum(Total), .groups = 'drop')
# Categorize vehicles and calculate totals
vehicles_by_type <- fleet_state %>%
mutate(vehicle_type = case_when(
`Combustível Veículo` %in% c("ELETRICO", "ELETRICO/FONTE INTERNA") ~ "Electric",
grepl("/ELETRICO", `Combustível Veículo`) | `Combustível Veículo` == "ELETRICO/FONTE EXTERNA" ~ "Hybrid",
TRUE ~ "Other"
)) %>%
group_by(UF, vehicle_type) %>%
summarise(total = sum(Total), .groups = 'drop') %>%
pivot_wider(
names_from = vehicle_type,
values_from = total,
values_fill = 0
) %>%
left_join(vehicles_per_state, by = "UF") %>%
mutate(
# Adjust 2021 values
Electric = if(year == 2021) Electric/10 else Electric,
Hybrid = if(year == 2021) Hybrid/10 else Hybrid,
Other = if(year == 2021) Other/10 else Other,
total_vehicles = if(year == 2021) total_vehicles/10 else total_vehicles,
# Calculate percentages
electric_percentage = scales::percent(Electric/total_vehicles, accuracy = 0.01),
hybrid_percentage = scales::percent(Hybrid/total_vehicles, accuracy = 0.01),
year = year
) %>%
filter(UF != "Sem Informação")
return(vehicles_by_type)
}
# Process all files and combine results
all_results <- lapply(file_paths, process_file)
combined_results <- bind_rows(all_results)
# Prepare state data frame
state_df$UF <- state_df$name_state %>%
stringi::stri_trans_general("Latin-ASCII") %>%
toupper()
# Final join with geographic information
final_result <- combined_results %>%
left_join(state_df, by = "UF") %>%
select(year, code_state, abbrev_state, name_state, code_region,
name_region, geom, Electric, Hybrid, Other,
total_vehicles, electric_percentage, hybrid_percentage)
# Store the result in the global environment
assign("fleet_analysis_results", final_result, envir = .GlobalEnv)
return(final_result)
}
create_fleet_analysis_function(file_paths, state_df)
# 3.2 Creating data sets for the plots -----------------------------------------
# Aggregate values for all states and years
yearly_results_aggregate <- fleet_analysis_results %>%
drop_na() %>%
group_by(year) %>%
summarize(Electric = sum(Electric),
Hybrid   = sum(Hybrid),
Other    = sum(Other),
Total   = sum(total_vehicles)) %>%
mutate(Share_electric = Electric/Total,
Share_hybrid   = Hybrid/Total)
# Observations per state
yearly_results_state <- fleet_analysis_results %>%
drop_na() %>%
group_by(year, name_state) %>%
summarize(Electric = sum(Electric),
Hybrid   = sum(Hybrid),
Other    = sum(Other),
Total   = sum(total_vehicles)) %>%
mutate(Share_electric = Electric/Total,
Share_hybrid   = Hybrid/Total)
# Pivoted table per category
yearly_results_agg_long <- yearly_results_aggregate %>%
select(year,Electric, Hybrid,Other) %>%
pivot_longer(
cols      = !year,
names_to  = "Category",
values_to = "Count"
)
View(yearly_results_state)
View(yearly_results_aggregate)
View(yearly_results_agg_long)
View(yearly_results_aggregate)
yearly_results_aggregate
if (!file.exists("./3_processed_data/fleet_yearly_state_wide.csv")) {
write_csv(yearly_results_aggregate,
file = "./3_processed_data/fleet_yearly_state_wide.csv")
} else {
print("File already exists in the repository")
}
if (!file.exists("./3_processed_data/fleet_yearly_state_long.csv")) {
write_csv(yearly_results_state,
file = "./3_processed_data/fleet_yearly_state_long.csv")
} else {
print("File already exists in the repository")
}
if (!file.exists("./3_processed_data/fleet_yearly_agg_long.csv")) {
write_csv(yearly_results_agg_long,
file = "./3_processed_data/fleet_yearly_agg_long.csv")
} else {
print("File already exists in the repository")
}
getwd()
query_2022 <- "
SELECT
dados.id_municipio AS id_municipio,
diretorio_id_municipio.nome AS id_municipio_nome,
dados.sigla_uf as sigla_uf,
dados.populacao as populacao,
dados.area as area,
dados.taxa_alfabetizacao as taxa_alfabetizacao,
dados.indice_envelhecimento as indice_envelhecimento,
dados.idade_mediana as idade_mediana,
dados.razao_sexo as razao_sexo
FROM `basedosdados.br_ibge_censo_2022.municipio` AS dados
LEFT JOIN (SELECT DISTINCT id_municipio,nome  FROM `basedosdados.br_bd_diretorios_brasil.municipio`) AS diretorio_id_municipio
ON dados.id_municipio = diretorio_id_municipio.id_municipio
"
# Writing the demographic info per city
pop_city <- read_sql(query_2022, billing_project_id = get_billing_id())
# Saving it as a .csv file
write_csv(pop_city, "./1_raw_data/0_demographics/pop_city.csv")
pop_data_MS <- read_sql(query_MS, billing_project_id = get_billing_id())
# Para carregar o dado direto no R
query_MS <- "
SELECT
dados.ano as ano,
dados.id_municipio AS id_municipio,
diretorio_id_municipio.nome AS id_municipio_nome,
dados.sexo as sexo,
dados.grupo_idade as grupo_idade,
dados.populacao as populacao
FROM `basedosdados.br_ms_populacao.municipio` AS dados
LEFT JOIN (SELECT DISTINCT id_municipio,nome  FROM `basedosdados.br_bd_diretorios_brasil.municipio`) AS diretorio_id_municipio
ON dados.id_municipio = diretorio_id_municipio.id_municipio
"
pop_data_MS <- read_sql(query_MS, billing_project_id = get_billing_id())
View(pop_data_MS)
if (!file.exists("./1_raw_data/pop_data_MS.csv")) {
write_csv(pop_data_MS,
file = "./3_processed_data/pop_data_MS.csv")
} else {
print("File already exists in the repository")
}
if (!file.exists("./1_raw_data/0_demographics/pop_data_MS.csv")) {
write_csv(pop_data_MS,
file = "./3_processed_data/pop_data_MS.csv")
} else {
print("File already exists in the repository")
}
if (!file.exists("./1_raw_data/0_demographics/pop_data_MS.csv")) {
write_csv(pop_data_MS,
file = "./1_raw_data/0_demographics/pop_data_MS.csv")
} else {
print("File already exists in the repository")
}
yearly_pop_data <- pop_data_MS %>%
group_by(ano) %>%
summarize(year = ano,
population = sum(populacao))
View(yearly_pop_data)
yearly_pop_data <- pop_data_MS %>%
group_by(ano) %>%
summarize(population = sum(populacao))
View(yearly_pop_data)
pop_city
yearly_pop_data_22 <- pop_city %>%
summarize(2022 = sum(populacao))
yearly_pop_data_22 <- pop_city %>%
summarize("2022" = sum(populacao))
View(yearly_pop_data_22)
if (!file.exists("./3_processed_data/yearly_pop_data.csv")) {
write_csv(yearly_pop_data,
file = "./3_processed_data/yearly_pop_data.csv")
} else {
print("File already exists in the repository")
}
if (!file.exists("./1_raw_data/4_fuel_consumption/fuel_raw_gasoline_data.csv")) {
write_csv(pop_data_MS,
file = "./1_raw_data/4_fuel_consumption/fuel_raw_gasoline_data.csv")
} else {
print("File already exists in the repository")
}
write_csv(pop_data_MS,
file = "./1_raw_data/4_fuel_consumption/fuel_raw_diesel_data_raw.csv")
# 1. Packages ------------------------------------------------------------------
source("./2_code/00_packages.R")
# 2. Raw dataframes ------------------------------------------------------------
# 2.1. Gasoline  ---------------------------------------------------------------
# Define the function
download_and_combine_gasoline_data <- function(start_year = 2000, end_year = 2023) {
# Base URL for the files
base_url <- "https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-estatisticos/de/arquivos-vendas-de-derivados-de-petroleo-e-biocombustiveis/gasolina-c/gasolina-c-municipio-"
# Initialize an empty list to store datasets
all_data <- list()
# Loop through each year
for (year in start_year:end_year) {
# Construct the URLs for .xlsx and .xls files
url_xlsx <- paste0(base_url, year, ".xlsx")
url_xls <- paste0(base_url, year, ".xls")
# Download the file to a temporary location
temp_file <- tempfile()
response <- GET(url_xlsx, write_disk(temp_file, overwrite = TRUE))
# Check if the .xlsx download was successful
if (response$status_code != 200) {
# Attempt to download the .xls file if .xlsx fails
response <- GET(url_xls, write_disk(temp_file, overwrite = TRUE))
}
# Check if either download was successful
if (response$status_code == 200) {
# Read the Excel file starting from row 5 and add a "year" column
data <- read_excel(temp_file, skip = 4) %>%
na.omit() %>%   # Remove rows with missing values
mutate(year = year)  # Add a column for the year
# Append the dataset to the list
all_data[[as.character(year)]] <- data
} else {
warning(paste("Failed to download data for year:", year))
}
}
# Combine all datasets into a single dataframe
combined_data <- bind_rows(all_data)
return(combined_data)
}
# Download all data on gasoline consumption using the function above
gasoline_data_raw <- download_and_combine_gasoline_data() %>%
mutate(municipio = ifelse(is.na(Município), Municípios, Município)) %>%
select(year, `CÓDIGO IBGE`, municipio, Vendas)  %>%
na.omit()
## Important: data above takes about 1 min to run
# Save data to a single xlsx file
if (!file.exists("./1_raw_data/4_fuel_consumption/fuel_raw_gasoline_data.csv")) {
write_csv(pop_data_MS,
file = "./1_raw_data/4_fuel_consumption/fuel_raw_gasoline_data.csv")
} else {
print("File already exists in the repository")
}
# 2.2. Diesel  -----------------------------------------------------------------
# Define the function
download_and_combine_diesel_data <- function(start_year = 2000, end_year = 2023) {
# Base URL for Diesel files
base_url <- "https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-estatisticos/de/arquivos-vendas-de-derivados-de-petroleo-e-biocombustiveis/oleo-diesel/oleo-diesel-municipio-"
# Initialize an empty list to store datasets
all_data <- list()
# Loop through each year
for (year in start_year:end_year) {
# Construct the URLs for .xlsx and .xls files
url_xlsx <- paste0(base_url, year, ".xlsx")
url_xls <- paste0(base_url, year, ".xls")
# Download the file to a temporary location
temp_file <- tempfile()
response <- GET(url_xlsx, write_disk(temp_file, overwrite = TRUE))
# Check if the .xlsx download was successful
if (response$status_code != 200) {
# Attempt to download the .xls file if .xlsx fails
response <- GET(url_xls, write_disk(temp_file, overwrite = TRUE))
}
# Check if either download was successful
if (response$status_code == 200) {
# Read the Excel file starting from row 5 and add a "year" column
data <- read_excel(temp_file, skip = 4) %>%
mutate(`CÓDIGO IBGE` = as.character(`CÓDIGO IBGE`)) %>%  # Ensure 'CÓDIGO IBGE' is a string
na.omit() %>%   # Remove rows with missing values
mutate(year = year)  # Add a column for the year
# Append the dataset to the list
all_data[[as.character(year)]] <- data
} else {
warning(paste("Failed to download data for year:", year))
}
}
# Combine all datasets into a single dataframe
combined_data <- bind_rows(all_data)
return(combined_data)
}
# Download all data on diesel consumption using the function above
diesel_data_raw <- download_and_combine_diesel_data(start_year = 2000, end_year = 2023)
## Important: running code above takes about 1 min to run
diesel_data_raw <- diesel_data_raw %>%
mutate(municipio = ifelse(is.na(Município), Municípios, Município)) %>%
select(year, `CÓDIGO IBGE`, municipio, Vendas)  %>%
na.omit()
# Save data to a single xlsx file
if (!file.exists("./1_raw_data/4_fuel_consumption/fuel_raw_diesel_data_raw.csv")) {
write_csv(diesel_data_raw,
file = "./1_raw_data/4_fuel_consumption/fuel_raw_diesel_data_raw.csv")
} else {
print("File already exists in the repository")
}
# 2.3. Ethanol  ----------------------------------------------------------------
# Define the function
download_and_combine_ethanol_data <- function(start_year = 2000, end_year = 2023) {
# Base URL for Ethanol files
base_url <- "https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-estatisticos/de/arquivos-vendas-de-derivados-de-petroleo-e-biocombustiveis/etanol-hidratado/etanol-hidratado-municipio-"
# Initialize an empty list to store datasets
all_data <- list()
# Loop through each year
for (year in start_year:end_year) {
# Construct the URLs for .xlsx and .xls files
url_xlsx <- paste0(base_url, year, ".xlsx")
url_xls <- paste0(base_url, year, ".xls")
# Download the file to a temporary location
temp_file <- tempfile()
response <- GET(url_xlsx, write_disk(temp_file, overwrite = TRUE))
# Check if the .xlsx download was successful
if (response$status_code != 200) {
# Attempt to download the .xls file if .xlsx fails
response <- GET(url_xls, write_disk(temp_file, overwrite = TRUE))
}
# Check if either download was successful
if (response$status_code == 200) {
# Read the Excel file starting from row 5 and add a "year" column
data <- read_excel(temp_file, skip = 4) %>%
mutate(`CÓDIGO IBGE` = as.character(`CÓDIGO IBGE`), # Ensure 'CÓDIGO IBGE' is a string
Vendas = as.numeric(Vendas)) %>%            # Convert 'Vendas' to numeric
na.omit() %>%   # Remove rows with missing values
mutate(year = year)  # Add a column for the year
# Append the dataset to the list
all_data[[as.character(year)]] <- data
} else {
warning(paste("Failed to download data for year:", year))
}
}
# Combine all datasets into a single dataframe
combined_data <- bind_rows(all_data)
return(combined_data)
}
# Download all data on ethanol consumption using the function above
ethanol_data_raw <- download_and_combine_ethanol_data(start_year = 2000, end_year = 2023)
ethanol_data_raw <- ethanol_data_raw %>%
na.omit()
# Save data to a single xlsx file
if (!file.exists("./1_raw_data/4_fuel_consumption/fuel_raw_ethanol_data.csv")) {
write_csv(ethanol_data_raw,
file = "./1_raw_data/4_fuel_consumption/fuel_raw_ethanol_data.csv")
} else {
print("File already exists in the repository")
}
# 3. Summarised data frames ----------------------------------------------------
gasoline_summary <- gasoline_data_raw %>%
filter(year >= 2012) %>%
group_by(year) %>%
summarise(total = sum(Vendas)) %>%
mutate(fuel = "gasoline")
diesel_summary <- diesel_data_raw %>%
filter(year >= 2012) %>%
group_by(year) %>%
summarise(total = sum(Vendas)) %>%
mutate(fuel = "diesel")
ethanol_summary <- ethanol_data_raw %>%
filter(year >= 2012) %>%
group_by(year) %>%
summarise(total = sum(Vendas)) %>%
mutate(fuel = "ethanol")
all_fuels_summary <- bind_rows(gasoline_summary,diesel_summary,ethanol_summary)
all_fuels_summary
ethanol_summary
if (!file.exists("./3_processed_data/fuel_yearly_agg_data_long.csv")) {
write_csv(all_fuels_summary,
file = "./3_processed_data/fuel_yearly_agg_data_long.csv")
} else {
print("File already exists in the repository")
}
if (!file.exists("./1_raw_data/0_demographics/pop_data_MS.csv")) {
write_csv(pop_data_MS,
file = "./1_raw_data/0_demographics/pop_data_MS.csv")
} else {
print("File already exists in the repository")
}
all_fuels_summary
all_fuels_summary_wide <- all_fuels_summary %>%
pivot_wider(
names_from = fuel,
values_from = total
)
View(all_fuels_summary_wide)
diesel_summary
if (!file.exists("./3_processed_data/fuel_yearly_agg_data_wide.csv")) {
write_csv(all_fuels_summary_wide,
file = "./3_processed_data/fuel_yearly_agg_data_wide.csv")
} else {
print("File already exists in the repository")
}
source("./2_code/00_packages.R")
fuel_yearly_agg_data_wide <- read_csv("3_processed_data/fuel_yearly_agg_data_wide.csv")
View(fuel_yearly_agg_data_wide)
fuel <- read_csv("3_processed_data/fuel_yearly_agg_data_wide.csv")
df_fuel <- read_csv("3_processed_data/fuel_yearly_agg_data_wide.csv")
df_fuel <- read_csv("3_processed_data/fuel_yearly_agg_data_wide.csv")
df_fleet       <- read_csv("3_processed_data/fleet_yearly_state_wide.csv")
df_fuel        <- read_csv("3_processed_data/fuel_yearly_agg_data_wide.csv")
df_population  <- read_csv("3_processed_data/yearly_pop_data.csv")
df_tax_revenue <- read_csv("3_processed_data/taxrev_federal_gasstation_fueltaxes.csv")
df_fleet       <- read_csv("3_processed_data/fleet_yearly_state_wide.csv")
View(df_fleet)
View(df_fuel)
View(df_population)
View(df_tax_revenue)
df_population <- df_population %>%
filter(ano >= 2013 & ano <= 2021) %>%
rename(year = ano)
df_fuel <- df_fuel %>%
filter(ano >= 2013 & ano <= 2021) %>%
rename(year = ano)
df_fuel <- df_fuel %>%
filter(year >= 2013 & year <= 2021)
View(df_tax_revenue)
df_tax_revenue <- df_tax_revenue %>%
mutate(year = as.numeric(substr(ano_mes_date, 1, 4)))
df_tax_revenue <- df_tax_revenue %>%
mutate(year = as.numeric(substr(ano_mes_date, 1, 4))) %>%
group_by(year) %>%
summarize(fuel_taxes = sum(fuel_taxes))
View(df_tax_revenue)
df_tax_revenue <- df_tax_revenue %>%
mutate(year = as.numeric(substr(ano_mes_date, 1, 4))) %>%
group_by(year) %>%
summarize(fuel_taxes = sum(fuel_taxes)) %>%
filter(ano >= 2013 & ano <= 2021) %>%
View(df_tax_revenue)
View(df_population)
df_tax_revenue <- df_tax_revenue %>%
mutate(year = as.numeric(substr(ano_mes_date, 1, 4))) %>%
group_by(year) %>%
summarize(fuel_taxes = sum(fuel_taxes)) %>%
filter(ano >= 2013 & ano <= 2021)
df_tax_revenue <- read_csv("3_processed_data/taxrev_federal_gasstation_fueltaxes.csv") # 2013 to 2024
df_tax_revenue <- df_tax_revenue %>%
mutate(year = as.numeric(substr(ano_mes_date, 1, 4))) %>%
group_by(year) %>%
summarize(fuel_taxes = sum(fuel_taxes)) %>%
filter(ano >= 2013 & ano <= 2021)
df_tax_revenue <- df_tax_revenue %>%
mutate(year = as.numeric(substr(ano_mes_date, 1, 4))) %>%
group_by(year) %>%
summarize(fuel_taxes = sum(fuel_taxes)) %>%
filter(year >= 2013 & year <= 2021)
df_fleet       <- df_fleet %>%
filter(year >= 2013 & year <= 2021)
df_all <- df_fleet %>%
left_join(df_population, df_fuel, df_tax_revenue, by = year)
df_all <- df_fleet %>%
left_join(df_population, df_fuel, df_tax_revenue, by = "year")
df_all <- df_fleet %>%
left_join(df_population, by = "year") %>%
left_join(df_tax_revenue, by = "year") %>%
left_join(df_fuel,        by = "year")
View(df_all)
rm(df_all)
df_all <- df_fleet %>%
left_join(df_population,  by = "year") %>%
left_join(df_tax_revenue, by = "year") %>%
left_join(df_fuel,        by = "year") %>%
mutate(
tax_per_capita = fuel_taxes/population
)
View(df_all)
library(Metrics)
install.packages("Metrics")
library(Metrics)
# Function to calculate RMSE
calculate_rmse <- function(model, data) {
predictions <- predict(model, data)
rmse(data$ev_count, predictions)
}
test_data <- df_all
# Compare RMSE for each model
lm_rmse <- calculate_rmse(lm_model, test_data)
xgb_rmse <- rmse(test_data$ev_count, predict(xgb_model, as.matrix(test_data %>% select(-ev_count))))
library(caret)
library(caret)
train_index <- createDataPartition(df_all$electric, p = 0.8, list = FALSE)
?createDataPartition
library(caret)
train_index <- caret::createDataPartition(df_all$electric, p = 0.8, list = FALSE)
?caret
install.packages("caret")
install.packages("caret")
library(caret)
set.seed(123)
train_index <- caret::createDataPartition(df_all$electric, p = 0.8, list = FALSE)
require(caret)
train_index <- caret::createDataPartition(df_all$electric, p = 0.8, list = FALSE)
train_index <- createDataPartition(df_all$electric, p = 0.8, list = FALSE)
pacman::p_load(
readr,        # Read CSV files
readxl,       # Read Excel files
dplyr,        # Data manipulation
tidyr,        # Data tidying and reshaping
ggplot2,      # Create data visualizations
scales,       # Format axes and legends (percentages, currencies)
stringr,      # String manipulation
lubridate,    # Date and time manipulation
basedosdados, # Access to Brazilian public data via BigQuery
geobr,        # Brazilian geographic data
sf,           # Handle spatial/geographic data
viridis,      # Color palettes for data visualization
stringi,      # Advanced string manipulation (e.g., Unicode support)
gt,           # Create beautiful tables for reporting results
webshot2,     # Capture screenshots of web pages or save HTML widgets as images
RColorBrewer, # Additional color palettes for plotting
httr,
Metrics,
caret
)
install.packages("caret")
